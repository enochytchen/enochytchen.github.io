<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Enoch Yi-Tung Chen</title>
    <link>https://enochytchen.com/</link>
      <atom:link href="https://enochytchen.com/index.xml" rel="self" type="application/rss+xml" />
    <description>Enoch Yi-Tung Chen</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 26 Oct 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://enochytchen.com/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Enoch Yi-Tung Chen</title>
      <link>https://enochytchen.com/</link>
    </image>
    
    <item>
      <title>Data management</title>
      <link>https://enochytchen.com/courses/biostatbasics/dataman/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/courses/biostatbasics/dataman/</guid>
      <description>&lt;h2 id=&#34;learning-outcomes&#34;&gt;Learning outcomes&lt;/h2&gt;
&lt;p&gt;In this section, you will learn how to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ensure the analysis is reproducible&lt;/li&gt;
&lt;li&gt;work coherently and efficiently with yourself&lt;/li&gt;
&lt;li&gt;ensure the project can be understood by others (supervisors, collaborators, and future readers)&lt;/li&gt;
&lt;li&gt;create a good work flow and enhance accuracy of work&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;course-notes&#34;&gt;Course notes&lt;/h2&gt;
&lt;p&gt;Slides can be downloaded (in PDF format) 
&lt;a href=&#34;DataManagement_EC_202010.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;study-notes&#34;&gt;Study notes&lt;/h2&gt;
&lt;p&gt;No study notes in this section&lt;/p&gt;
&lt;h2 id=&#34;excercise&#34;&gt;Excercise&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Data Clearance</title>
      <link>https://enochytchen.com/courses/biostatbasics/dataclearance/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/courses/biostatbasics/dataclearance/</guid>
      <description>&lt;h2 id=&#34;learning-outcomes&#34;&gt;Learning outcomes&lt;/h2&gt;
&lt;h2 id=&#34;in-this-section-you-will-learn-how-to&#34;&gt;In this section, you will learn how to&lt;/h2&gt;
&lt;h2 id=&#34;video-lectures&#34;&gt;Video lectures&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/BwknA6aGqvs&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;course-notes&#34;&gt;Course notes&lt;/h2&gt;
&lt;p&gt;Slides can be downloaded (in pdf format) 
&lt;a href=&#34;data_clearance_EC.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;study-notes&#34;&gt;Study notes&lt;/h2&gt;
&lt;p&gt;No study notes for this session&lt;/p&gt;
&lt;h2 id=&#34;stata-syntax-in-the-slides&#34;&gt;Stata syntax in the slides&lt;/h2&gt;
&lt;p&gt;Stata codes be downloaded (do file) 
&lt;a href=&#34;data_clearance.do&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Summary Statistics</title>
      <link>https://enochytchen.com/courses/biostatbasics/sumstat/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/courses/biostatbasics/sumstat/</guid>
      <description>&lt;h2 id=&#34;learning-outcomes&#34;&gt;Learning outcomes&lt;/h2&gt;
&lt;p&gt;In this section, you will learn how to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;get to know the data by performing &lt;code&gt;summarize&lt;/code&gt;, &lt;code&gt;describe&lt;/code&gt;, &lt;code&gt;codebook&lt;/code&gt;, &lt;code&gt;list&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;measure central tendency of the data (mean, median, amd mode)&lt;/li&gt;
&lt;li&gt;measure dispersion of the data (range, interquartile range, variance, and standard deviation)&lt;/li&gt;
&lt;li&gt;make a two-by-two table ad interpret relative risk and odds ratio from it by using &lt;code&gt;csi&lt;/code&gt; in &lt;code&gt;epitab&lt;/code&gt; package&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;video-lectures&#34;&gt;Video lectures&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/BwknA6aGqvs&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;course-notes&#34;&gt;Course notes&lt;/h2&gt;
&lt;p&gt;Slides can be downloaded (in pdf format) 
&lt;a href=&#34;&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;study-notes&#34;&gt;Study notes&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;&#34;&gt;Ch1 Descriptive statistics&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;stata-syntax-in-the-slides&#34;&gt;Stata syntax in the slides&lt;/h2&gt;
&lt;p&gt;Stata codes be downloaded (do file) 
&lt;a href=&#34;&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graphs</title>
      <link>https://enochytchen.com/courses/biostatbasics/graphs/</link>
      <pubDate>Thu, 24 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/courses/biostatbasics/graphs/</guid>
      <description>&lt;h2 id=&#34;learning-outcomes&#34;&gt;Learning outcomes&lt;/h2&gt;
&lt;p&gt;In this section, you will learn how to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;use Stata to create histograms, bar charts, box plots, scatter plots, and line graphs&lt;/li&gt;
&lt;li&gt;edit and customise graphs in &lt;code&gt;twoway&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;export graph in any format using &lt;code&gt;graph export&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;video-lectures&#34;&gt;Video lectures&lt;/h2&gt;
&lt;h2 id=&#34;course-notes&#34;&gt;Course notes&lt;/h2&gt;
&lt;p&gt;Slides can be downloaded (in pdf format) 
&lt;a href=&#34;&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;study-notes&#34;&gt;Study notes&lt;/h2&gt;
&lt;p&gt;Please refer to &lt;strong&gt;1.3 Data presentation&lt;/strong&gt; in  
&lt;a href=&#34;&#34;&gt;Ch1 Descriptive statistics&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;stata-syntax-shown-in-the-lecture&#34;&gt;Stata syntax shown in the lecture&lt;/h2&gt;
&lt;p&gt;Stata codes be downloaded (do file) 
&lt;a href=&#34;&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exercises</title>
      <link>https://enochytchen.com/cansurv/exercises/</link>
      <pubDate>Mon, 26 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/cansurv/exercises/</guid>
      <description>&lt;p&gt;This is a testing page for using Stata Markdown.&lt;/p&gt;
&lt;h2 id=&#34;stata-syntax-shown-in-the-lecture&#34;&gt;Stata syntax shown in the lecture&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;th&gt;Markstat&lt;/th&gt;
&lt;th&gt;Questions&lt;/th&gt;
&lt;th&gt;Solutions&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Stata&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Cox regression with observed (all-cause) mortality as the outcome&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://enochytchen.com/cansurv/exercises/q122.stmd&#34;&gt;Q122.stmd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://enochytchen.com/cansurv/exercises/q122.pdf&#34;&gt;Q122&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://enochytchen.com/cansurv/exercises/s122.pdf&#34;&gt;S122&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
&lt;a href=&#34;https://enochytchen.com/cansurv/exercises/s122.do&#34;&gt;s122.do&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Calculating excess and ‘avoidable’ deaths from life tables&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://enochytchen.com/cansurv/exercises/q282.stmd&#34;&gt;Q282.stmd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://enochytchen.com/cansurv/exercises/q282.pdf&#34;&gt;Q282&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://enochytchen.com/cansurv/exercises/s282.pdf&#34;&gt;S282&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
&lt;a href=&#34;https://enochytchen.com/cansurv/exercises/s282.do&#34;&gt;s282.do&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Confidence Intervals</title>
      <link>https://enochytchen.com/courses/biostatbasics/confidence/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/courses/biostatbasics/confidence/</guid>
      <description>&lt;h2 id=&#34;learning-outcomes&#34;&gt;Learning outcomes&lt;/h2&gt;
&lt;h2 id=&#34;study-notes&#34;&gt;Study notes&lt;/h2&gt;
&lt;p&gt;Study
cite goldman and pagemo&lt;/p&gt;
&lt;h2 id=&#34;course-notes&#34;&gt;Course notes&lt;/h2&gt;
&lt;p&gt;Slides can be downloaded (in PDF format) here.&lt;/p&gt;
&lt;h2 id=&#34;stata-syntax-shown-in-the-lecture&#34;&gt;Stata syntax shown in the lecture&lt;/h2&gt;
&lt;p&gt;Stata:&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hypothesis tests</title>
      <link>https://enochytchen.com/courses/biostatbasics/hypotest/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/courses/biostatbasics/hypotest/</guid>
      <description>&lt;h2 id=&#34;learning-outcomes&#34;&gt;Learning outcomes&lt;/h2&gt;
&lt;h2 id=&#34;study-notes&#34;&gt;Study notes&lt;/h2&gt;
&lt;p&gt;Study
cite goldman and pagemo&lt;/p&gt;
&lt;h2 id=&#34;course-notes&#34;&gt;Course notes&lt;/h2&gt;
&lt;p&gt;Slides can be downloaded (in PDF format) here.&lt;/p&gt;
&lt;h2 id=&#34;stata-syntax-shown-in-the-lecture&#34;&gt;Stata syntax shown in the lecture&lt;/h2&gt;
&lt;p&gt;Stata:&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Untied time data → Tied</title>
      <link>https://enochytchen.com/tutorials/relsurv/untied/</link>
      <pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/tutorials/relsurv/untied/</guid>
      <description>&lt;p&gt;(Not completed yet)&lt;/p&gt;
&lt;p&gt;The codes used in this tutorial are available below.&lt;br&gt;

&lt;a href=&#34;https://enochytchen.com/tutorials/relsurv/untied/using_sim.R&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;rs.surv&lt;/a&gt;&lt;br&gt;

&lt;a href=&#34;https://enochytchen.com/tutorials/relsurv/untied/using_sim.do&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stns, stpp, strs, stnet&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This example showed how the relative survival estimates change given more and more ties are added into the data.&lt;/p&gt;
&lt;h3 id=&#34;dataset&#34;&gt;Dataset&lt;/h3&gt;
&lt;p&gt;The dataset (&lt;code&gt;scenario2_1.dta&lt;/code&gt;) is a simulated data, containing 1000 subjects. The original survival time is untied data with 651 distinct values in years (min: 0.0027; max: 12). We then added ties into the data by flooring the time into discrete days, weeks, months, quaters, or years. More ties are added (i.e., less distinct values) as the time interval becomes larger (days→years). If any survival time became 0 due to flooring, we then made it 0.5 of the time interval (e.g., 0.5 months).&lt;/p&gt;
&lt;p&gt;The following table shows how the time was treated in different units.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Time variable&lt;/th&gt;
&lt;th&gt;Discrete time in&lt;/th&gt;
&lt;th&gt;Stata code&lt;/th&gt;
&lt;th&gt;Distinct values&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;tt1&lt;/td&gt;
&lt;td&gt;Original continuous time&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;651&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tt2&lt;/td&gt;
&lt;td&gt;Days&lt;/td&gt;
&lt;td&gt;(floor(tt1*365.241) + 0.5) /365.241&lt;/td&gt;
&lt;td&gt;569&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tt3&lt;/td&gt;
&lt;td&gt;Weeks&lt;/td&gt;
&lt;td&gt;(floor(tt1*52.177)  + 0.5) /52.177&lt;/td&gt;
&lt;td&gt;332&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tt4&lt;/td&gt;
&lt;td&gt;Months&lt;/td&gt;
&lt;td&gt;(floor(tt1*12)      + 0.5) /12&lt;/td&gt;
&lt;td&gt;132&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tt5&lt;/td&gt;
&lt;td&gt;Quarters&lt;/td&gt;
&lt;td&gt;(floor(tt1*4)       + 0.5) /4&lt;/td&gt;
&lt;td&gt;49&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tt6&lt;/td&gt;
&lt;td&gt;Years&lt;/td&gt;
&lt;td&gt;(floor(tt1)         + 0.5)&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;relative-survival-estimates&#34;&gt;Relative survival estimates&lt;/h3&gt;
&lt;p&gt;The following tables show the estimates of 1-, 5-, and 10-year relative survival (RS) using the Pohar-Perme estimator by &lt;code&gt;rs.surv&lt;/code&gt;, &lt;code&gt;stpp&lt;/code&gt;, &lt;code&gt;strs&lt;/code&gt;, and &lt;code&gt;stnet&lt;/code&gt;. To make the tables look tidier, here we dismissed the 95% CI, which however can be found in the outputs of the syntax.&lt;/p&gt;
&lt;h4 id=&#34;rssurv&#34;&gt;rs.surv()&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Time &lt;br/&gt; (year)&lt;/th&gt;
&lt;th&gt;tt1&lt;br/&gt; original&lt;/th&gt;
&lt;th&gt;tt2 &lt;br/&gt; days&lt;/th&gt;
&lt;th&gt;tt3  &lt;br/&gt; weeks&lt;/th&gt;
&lt;th&gt;tt4  &lt;br/&gt; months&lt;/th&gt;
&lt;th&gt;tt5  &lt;br/&gt; quarters&lt;/th&gt;
&lt;th&gt;tt6  &lt;br/&gt; years&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.797&lt;/td&gt;
&lt;td&gt;0.797&lt;/td&gt;
&lt;td&gt;0.797&lt;/td&gt;
&lt;td&gt;0.790&lt;/td&gt;
&lt;td&gt;0.796&lt;/td&gt;
&lt;td&gt;0.788&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;0.618&lt;/td&gt;
&lt;td&gt;0.618&lt;/td&gt;
&lt;td&gt;0.618&lt;/td&gt;
&lt;td&gt;0.618&lt;/td&gt;
&lt;td&gt;0.617&lt;/td&gt;
&lt;td&gt;0.613&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0.534&lt;/td&gt;
&lt;td&gt;0.534&lt;/td&gt;
&lt;td&gt;0.534&lt;/td&gt;
&lt;td&gt;0.536&lt;/td&gt;
&lt;td&gt;0.535&lt;/td&gt;
&lt;td&gt;0.529&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;stns&#34;&gt;stns&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Time &lt;br/&gt; (year)&lt;/th&gt;
&lt;th&gt;tt1&lt;br/&gt; original&lt;/th&gt;
&lt;th&gt;tt2 &lt;br/&gt; days&lt;/th&gt;
&lt;th&gt;tt3  &lt;br/&gt; weeks&lt;/th&gt;
&lt;th&gt;tt4  &lt;br/&gt; months&lt;/th&gt;
&lt;th&gt;tt5  &lt;br/&gt; quarters&lt;/th&gt;
&lt;th&gt;tt6  &lt;br/&gt; years&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.797&lt;/td&gt;
&lt;td&gt;0.797&lt;/td&gt;
&lt;td&gt;0.796&lt;/td&gt;
&lt;td&gt;0.790&lt;/td&gt;
&lt;td&gt;0.777&lt;/td&gt;
&lt;td&gt;0.711&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;0.613&lt;/td&gt;
&lt;td&gt;0.613&lt;/td&gt;
&lt;td&gt;0.613&lt;/td&gt;
&lt;td&gt;0.614&lt;/td&gt;
&lt;td&gt;0.604&lt;/td&gt;
&lt;td&gt;0.600&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0.512&lt;/td&gt;
&lt;td&gt;0.512&lt;/td&gt;
&lt;td&gt;0.512&lt;/td&gt;
&lt;td&gt;0.514&lt;/td&gt;
&lt;td&gt;0.513&lt;/td&gt;
&lt;td&gt;0.510&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;stpp&#34;&gt;stpp&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Time &lt;br/&gt; (year)&lt;/th&gt;
&lt;th&gt;tt1&lt;br/&gt; original&lt;/th&gt;
&lt;th&gt;tt2 &lt;br/&gt; days&lt;/th&gt;
&lt;th&gt;tt3  &lt;br/&gt; weeks&lt;/th&gt;
&lt;th&gt;tt4  &lt;br/&gt; months&lt;/th&gt;
&lt;th&gt;tt5  &lt;br/&gt; quarters&lt;/th&gt;
&lt;th&gt;tt6  &lt;br/&gt; years&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.797&lt;/td&gt;
&lt;td&gt;0.797&lt;/td&gt;
&lt;td&gt;0.796&lt;/td&gt;
&lt;td&gt;0.790&lt;/td&gt;
&lt;td&gt;0.777&lt;/td&gt;
&lt;td&gt;0.709&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;0.613&lt;/td&gt;
&lt;td&gt;0.613&lt;/td&gt;
&lt;td&gt;0.613&lt;/td&gt;
&lt;td&gt;0.613&lt;/td&gt;
&lt;td&gt;0.603&lt;/td&gt;
&lt;td&gt;0.595&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0.512&lt;/td&gt;
&lt;td&gt;0.512&lt;/td&gt;
&lt;td&gt;0.512&lt;/td&gt;
&lt;td&gt;0.509&lt;/td&gt;
&lt;td&gt;0.502&lt;/td&gt;
&lt;td&gt;0.484&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;strs&#34;&gt;strs&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Time &lt;br/&gt; (year)&lt;/th&gt;
&lt;th&gt;tt1&lt;br/&gt; original&lt;/th&gt;
&lt;th&gt;tt2 &lt;br/&gt; days&lt;/th&gt;
&lt;th&gt;tt3  &lt;br/&gt; weeks&lt;/th&gt;
&lt;th&gt;tt4  &lt;br/&gt; months&lt;/th&gt;
&lt;th&gt;tt5  &lt;br/&gt; quarters&lt;/th&gt;
&lt;th&gt;tt6  &lt;br/&gt; years&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.798&lt;/td&gt;
&lt;td&gt;0.797&lt;/td&gt;
&lt;td&gt;0.795&lt;/td&gt;
&lt;td&gt;0.792&lt;/td&gt;
&lt;td&gt;0.778&lt;/td&gt;
&lt;td&gt;0.732&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;0.612&lt;/td&gt;
&lt;td&gt;0.612&lt;/td&gt;
&lt;td&gt;0.612&lt;/td&gt;
&lt;td&gt;0.616&lt;/td&gt;
&lt;td&gt;0.605&lt;/td&gt;
&lt;td&gt;0.617&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0.513&lt;/td&gt;
&lt;td&gt;0.513&lt;/td&gt;
&lt;td&gt;0.513&lt;/td&gt;
&lt;td&gt;0.512&lt;/td&gt;
&lt;td&gt;0.505&lt;/td&gt;
&lt;td&gt;0.506&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;stnet&#34;&gt;stnet&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Time &lt;br/&gt; (year)&lt;/th&gt;
&lt;th&gt;tt1&lt;br/&gt; original&lt;/th&gt;
&lt;th&gt;tt2 &lt;br/&gt; days&lt;/th&gt;
&lt;th&gt;tt3  &lt;br/&gt; weeks&lt;/th&gt;
&lt;th&gt;tt4  &lt;br/&gt; months&lt;/th&gt;
&lt;th&gt;tt5  &lt;br/&gt; quarters&lt;/th&gt;
&lt;th&gt;tt6  &lt;br/&gt; years&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.798&lt;/td&gt;
&lt;td&gt;0.797&lt;/td&gt;
&lt;td&gt;0.795&lt;/td&gt;
&lt;td&gt;0.798&lt;/td&gt;
&lt;td&gt;0.798&lt;/td&gt;
&lt;td&gt;0.799&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;0.612&lt;/td&gt;
&lt;td&gt;0.612&lt;/td&gt;
&lt;td&gt;0.612&lt;/td&gt;
&lt;td&gt;0.612&lt;/td&gt;
&lt;td&gt;0.613&lt;/td&gt;
&lt;td&gt;0.614&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0.513&lt;/td&gt;
&lt;td&gt;0.513&lt;/td&gt;
&lt;td&gt;0.513&lt;/td&gt;
&lt;td&gt;0.513&lt;/td&gt;
&lt;td&gt;0.513&lt;/td&gt;
&lt;td&gt;0.514&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;explanation&#34;&gt;Explanation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Generally, introducing ties into the data did not change the esitmates of relative survival no matter which package was used for calculation in this case. One exception happened if discrete time was made into years (&lt;code&gt;tt6&lt;/code&gt;), which merely 13 distinct values exist, &lt;code&gt;rs.surv()&lt;/code&gt; and &lt;code&gt;strs&lt;/code&gt; gave slightly lower estimates for 1-year relative survival (0.788 and 0.732 separately);  &lt;code&gt;stns&lt;/code&gt; and &lt;code&gt;stpp&lt;/code&gt; gave much lower survival, particularly in 1-year net survival; surprisingly, the output estimated by &lt;code&gt;stnet&lt;/code&gt;almost did not change given heavy ties were added.&lt;/li&gt;
&lt;li&gt;One thing we should bear in mind is that introducing ties to the data has in fact changed the original data. I tried to add ties in a sensible way and not to change the order of the data as much as possible. However, I am innocent of the lower or higher estimates  &lt;code&gt;rs.surv()&lt;/code&gt;, &lt;code&gt;stns&lt;/code&gt;, &lt;code&gt;stpp&lt;/code&gt;, and &lt;code&gt;strs&lt;/code&gt; gave.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;It is common that the data from cancer register has tied time, e.g., due to protection on patients&amp;rsquo; privacy. As estimating survival, we should pay attention to the potential change on the estimates given the amount of tie is introduced.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Eloranta2020</title>
      <link>https://enochytchen.com/tutorials/learningrs/eloranta2020/</link>
      <pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/tutorials/learningrs/eloranta2020/</guid>
      <description>&lt;h3 id=&#34;title&#34;&gt;Title&lt;/h3&gt;
&lt;p&gt;Cancer survival statistics for patients and healthcare professionals–a tutorial of real‐world data analysis&lt;/p&gt;
&lt;h3 id=&#34;authors&#34;&gt;Authors&lt;/h3&gt;
&lt;p&gt;Eloranta S, Smedby KE, Dickman PW, Andersson TM&lt;/p&gt;
&lt;h3 id=&#34;notes&#34;&gt;Notes&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Why do we use net survival?&lt;/strong&gt;&lt;br&gt;
We want to compare survival between groups and over time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Definition of net survival&lt;/strong&gt;: In a hypothetical world, cancer patients can only die from the cancer of interest.&lt;/li&gt;
&lt;li&gt;Comparison between&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cause-specific survival&lt;/strong&gt;:&lt;br&gt;
a. requires information on cause-specific deaths; deaths due to cancer/other than caner&lt;br&gt;
b. cause-specific death is not always complete or available.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Relative survival&lt;/strong&gt;:&lt;br&gt;
a. does not require information on cause-specific deaths&lt;br&gt;
b. requires a reference population, e.g., life-table data&lt;br&gt;
c. 
&lt;a href=&#34;https://enochytchen.com/post/analogue/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the mortality analogue of relative survival is excess mortality&lt;/a&gt;, which captures both direct and indirect mortality due to cancer.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Competeing events&lt;/strong&gt;&lt;br&gt;
Net survival measure is a clever way to compare survival between different groups, but in the real world, competing events exist.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loss of life expectancy&lt;/strong&gt;: the number of life years a cancer patient is estimated to lose.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;p&gt;Eloranta S, Smedby KE, Dickman PW, Andersson TM. Cancer survival statistics for patients and healthcare professionals–a tutorial of real‐world data analysis. Journal of Internal Medicine. 2020.
doi: 
&lt;a href=&#34;https://doi.org/10.1111/joim.13139&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1111/joim.13139&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Excess hazard is an analogue of relative survival. How come!?</title>
      <link>https://enochytchen.com/post/analogue/</link>
      <pubDate>Sat, 03 Oct 2020 12:46:05 +0200</pubDate>
      <guid>https://enochytchen.com/post/analogue/</guid>
      <description>&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#basics-of-survival-analysis&#34;&gt;Basics of survival analysis&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#proof-of-relative-survival&#34;&gt;Proof of relative survival&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;p&gt;It was mentioned numerous times in different articles that excess hazard is the analogue of relative survival on the hazard scale (1-4). However, how is it derived from?&lt;/p&gt;
&lt;p&gt;We first look into the basic definition of relative survival and excess hazard. Relative survival, $R(t)$, is defined as the ratio between the survival of the cancer patient cohort, $S(t)$, and the reference population, $S^*(t)$, whereas excess hazard, $\lambda (t)$, is the all-cause hazard, $h(t)$, minus the expected hazard, $h^*(t)$.
\begin{equation}
R(t) = \frac{S(t)}{S^*(t)}
\end{equation}
\begin{equation}
\lambda (t) = h(t) - h^*(t)
\end{equation}&lt;/p&gt;
&lt;h3 id=&#34;basics-of-survival-analysis&#34;&gt;Basics of survival analysis&lt;/h3&gt;
&lt;h4 id=&#34;survival-function&#34;&gt;Survival function&lt;/h4&gt;
&lt;p&gt;To illustrate the relationship in between these two terms, we need to come back to some basics of hazard and survival (5).
First, in almost every chapter one of any survival analysis book, you can find the definition of cumulative distribution function (c.d.f.) of a time $T$ variable, giving the probablity that the event has occurred as time is less than $t$.&lt;/p&gt;
&lt;p&gt;\begin{equation}
F(t)=\operatorname{P}(T&amp;lt;t)
\end{equation}&lt;/p&gt;
&lt;p&gt;The complement of this c.d.f. is survival function, , which is a &lt;strong&gt;proportion&lt;/strong&gt;, shown as
\begin{equation}
S(t)=\operatorname{P}(T \geq t)=1-F(t)=\int_{t}^{\infty} f(x) d x,
\end{equation}
which is defined as the probability that the event has not occurred by time $t$. That is, for example, the probability that the patient is still alive by time $t$, where $f(t)$ is the probability density function (p.d.f.). And $-f(t)$ is the derivative of $S(t)$.
$$\begin{eqnarray}
\frac{d S(t)}{dt} &amp;amp;=&amp;amp; \frac{d}{dt} \int_{t}^{\infty} f(x) d x \\\&lt;br&gt;
&amp;amp;=&amp;amp; -f(t)
\end{eqnarray}$$&lt;/p&gt;
&lt;h4 id=&#34;hazard-function&#34;&gt;Hazard function&lt;/h4&gt;
&lt;p&gt;We have to know by heart that the hazard function is the instantaneous rate of occurrence of the event, which is a &lt;strong&gt;rate&lt;/strong&gt; (event occurrence per unit of time).&lt;/p&gt;
&lt;p&gt;\begin{equation}
h(t)=\lim _{d t \rightarrow 0} \frac{\operatorname{P}(t \leq T&amp;lt;t+d t \mid T \geq t)}{d t}
\end{equation}&lt;/p&gt;
&lt;p&gt;Let us take a look at the numerator itself, which is a conditional probability.
\begin{equation}
\operatorname{P}(t \leq T&amp;lt;t+d t \mid T \geq t) = \frac{P(t \leq T&amp;lt;t+dt )}{P(T\geq t)},
\end{equation}
where the denominator part is in fact the survival function, $S(t)$, and the numerator part means the probability that the event happens $[t, t+dt)$, which is $f(t)dt$. So we then extend the equation:
$$\begin{eqnarray}
\operatorname{P}(t \leq T&amp;lt;t+d t \mid T \geq t) &amp;amp;=&amp;amp; \frac{P(t \leq T&amp;lt;t+dt )}{P(T\geq t)}&lt;br&gt;
\\\ &amp;amp;=&amp;amp;\frac{f(t)dt}{S(t)}
\end{eqnarray}$$
Dividing both sides by $dt$, it gives the relationship between the hazard function and the survival function, which is
$$\begin{eqnarray}
h(t) &amp;amp;=&amp;amp; \frac{f(t)}{S(t)} \\\&lt;br&gt;
&amp;amp;=&amp;amp; \frac{\frac{-d S(t)}{dt}}{S(t)} \\\&lt;br&gt;
&amp;amp;=&amp;amp; \frac{-{S}&#39;(t)}{S(t)}
&amp;amp;=&amp;amp; \frac{-d \ln S(t)}{dt}
\end{eqnarray} $$
(Please catch up your Calculus 101: $\frac{d \ln x}{dx} = \frac{1}{x}$)&lt;/p&gt;
&lt;p&gt;If we rewrite the equation above, we will obtain:
\begin{equation}
\ln S(t) = -\int_{0}^{t} h(x) d x
\end{equation}&lt;/p&gt;
&lt;p&gt;$$\begin{eqnarray}
S(t) &amp;amp;=&amp;amp; exp(-\int_{0}^{t} h(x) d x) \\\&lt;br&gt;
&amp;amp;=&amp;amp; exp(-H(t))
\end{eqnarray}$$&lt;/p&gt;
&lt;p&gt;This is pretty! Then we get to know the cumulative hazard function.&lt;/p&gt;
&lt;h4 id=&#34;cumulative-hazard-function&#34;&gt;Cumulative hazard function&lt;/h4&gt;
&lt;p&gt;The cumulative hazard function is the integral from 0 to time $t$, defined as
\begin{equation}
H(t)=\int_{0}^{t} h(x) d x.
\end{equation}
Thus, it is easy to understand that the hazard function is the derivative of the cumulative hazard function.
\begin{equation}
h(t) = \frac{d H(t)}{dt}
\end{equation}&lt;/p&gt;
&lt;h3 id=&#34;proof-of-relative-survival&#34;&gt;Proof of relative survival&lt;/h3&gt;
&lt;p&gt;\begin{equation}
R(t) = \frac{S(t)}{S^*(t)}
\end{equation}
First, by defintion of the relationship between the cumulative hazard function and the survival function, we will obtain
\begin{equation}
exp(- \Lambda (t)) = \frac{exp(- H(t))}{exp(-H^*(t))} \\\&lt;br&gt;
\end{equation}
\begin{equation}
exp(- \Lambda (t)) = exp(- H(t) + H^*(t))
\end{equation}
\begin{equation}
\Lambda (t) = H(t) - H^*(t)
\end{equation}&lt;/p&gt;
&lt;p&gt;Then we got the cumulative excess hazard, $\Lambda (t)$, is the difference between the cumulative all-cause  hazard (of the cancer patient cohort) and the cumulative expected hazard (of the reference population). Then, take the derivative of both sides, shown as:&lt;/p&gt;
&lt;p&gt;\begin{equation}
\frac{d \int_{0}^{t} \lambda(x) d x }{dt} = \frac{d \int_{0}^{t} h(x) d x }{dt} - \frac{d \int_{0}^{t} h^*(x) d x }{dt},
\end{equation}
which is exactly,&lt;/p&gt;
&lt;p&gt;\begin{equation}
\lambda (t) = h(t) - h^*(t)
\end{equation}&lt;/p&gt;
&lt;p&gt;This is fantastic!
Now you know why excess hazard is the hazard analogue of relative survival.&lt;/p&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Andersson TML, Dickman PW, Eloranta S, Lambe M, Lambert PC. Estimating the loss in expectation of life due to cancer using flexible parametric survival models. Statistics in Medicine 2013;32:5286–5300.&lt;/li&gt;
&lt;li&gt;Andersson T. Quantifying cancer patient survival: extensions and applications of cure models and life expectancy estimation. Phd thesis, Karolinska Institutet, 2013.&lt;/li&gt;
&lt;li&gt;Eloranta S. Development and Application of Statistical Methods for Population-Based Cancer
Patient Survival. Phd thesis, Karolinska Institutet, 2013.&lt;/li&gt;
&lt;li&gt;Eloranta S, Smedby KE, Dickman PW, Andersson TM. Cancer survival statistics for patients and healthcare professionals–a tutorial of real‐world data analysis. Journal of Internal Medicine. 2020.&lt;/li&gt;
&lt;li&gt;Germán Rodríguez. Generalized Linear Models: Survival Models. &lt;a href=&#34;https://data.princeton.edu&#34;&gt;https://data.princeton.edu&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Tied time data → Untied time data</title>
      <link>https://enochytchen.com/tutorials/relsurv/tied/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/tutorials/relsurv/tied/</guid>
      <description>&lt;p&gt;The codes used in this tutorial are available below.&lt;br&gt;

&lt;a href=&#34;https://enochytchen.com/tutorials/relsurv/tied/rs.surv.R&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;rs.surv&lt;/a&gt;&lt;br&gt;

&lt;a href=&#34;https://enochytchen.com/tutorials/relsurv/tied/using_colon_tied.do&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stns, stpp, strs, stnet (original tied data)&lt;/a&gt;&lt;br&gt;

&lt;a href=&#34;https://enochytchen.com/tutorials/relsurv/tied/using_colon_untied.do&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stns, stpp, strs, stnet (untied data)&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;settings&#34;&gt;Settings&lt;/h3&gt;
&lt;p&gt;This tutorial first used the colon.dta, which is originally a tied survival time data, to generate the relative survival estimates of 1-, 5-, and 10-year relative survival using the Pohar-Perme estimator (1), by &lt;code&gt;rs.surv()&lt;/code&gt; in R, &lt;code&gt;stpp&lt;/code&gt;,  &lt;code&gt;strs&lt;/code&gt;,  &lt;code&gt;stnet&lt;/code&gt; in Stata. In the second part, an small epislon ~ $Norm(0, 0.01)$ was added into each individual&amp;rsquo;s survival time to make no individual have exactly the same survival time (to untie the data).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Survival time was calculated by (date of exit - date of diagnosis).&lt;/li&gt;
&lt;li&gt;We define failure as &lt;code&gt;status == 1 2 &lt;/code&gt; (died from cancer or other causes).&lt;/li&gt;
&lt;li&gt;In &lt;code&gt;strs&lt;/code&gt;, &lt;code&gt;ht&lt;/code&gt; (hazard transformation) must be specified to command the survival be calculated by transforming cumulative excess hazard ($\lambda$) instead of an actuarial approach (default) (2). However, in &lt;code&gt;stnet&lt;/code&gt;, by default, survival is calculated by using hazard transformation.&lt;/li&gt;
&lt;li&gt;In &lt;code&gt;strs&lt;/code&gt; and &lt;code&gt;stnet&lt;/code&gt;, monthly intervals were calculated  up to ten years by specifying &lt;code&gt;br(0(`=1/12&#39;)10)&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;To make the tables look tidier, here we dismissed the 95% CI, which however can be found in the outputs of the syntax.
The esimates of 1-, 5-, and 10-year relative survival by each program are shown below:&lt;/p&gt;
&lt;h4 id=&#34;using-colondta-original-tied-time-data&#34;&gt;Using colon.dta (original tied time data)&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;t&lt;/th&gt;
&lt;th&gt;rs.surv&lt;/th&gt;
&lt;th&gt;stns&lt;/th&gt;
&lt;th&gt;stpp&lt;/th&gt;
&lt;th&gt;strs&lt;/th&gt;
&lt;th&gt;stnet&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.676&lt;/td&gt;
&lt;td&gt;0.677&lt;/td&gt;
&lt;td&gt;0.676&lt;/td&gt;
&lt;td&gt;0.677&lt;/td&gt;
&lt;td&gt;0.677&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;0.473&lt;/td&gt;
&lt;td&gt;0.474&lt;/td&gt;
&lt;td&gt;0.473&lt;/td&gt;
&lt;td&gt;0.474&lt;/td&gt;
&lt;td&gt;0.474&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0.433&lt;/td&gt;
&lt;td&gt;0.437&lt;/td&gt;
&lt;td&gt;0.434&lt;/td&gt;
&lt;td&gt;0.434&lt;/td&gt;
&lt;td&gt;0.434&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;using-colondta-untied-time-data&#34;&gt;Using colon.dta (untied time data)&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;t&lt;/th&gt;
&lt;th&gt;rs.surv&lt;/th&gt;
&lt;th&gt;stns&lt;/th&gt;
&lt;th&gt;stpp&lt;/th&gt;
&lt;th&gt;strs&lt;/th&gt;
&lt;th&gt;stnet&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.676&lt;/td&gt;
&lt;td&gt;0.677&lt;/td&gt;
&lt;td&gt;0.677&lt;/td&gt;
&lt;td&gt;0.677&lt;/td&gt;
&lt;td&gt;0.677&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;0.472&lt;/td&gt;
&lt;td&gt;0.474&lt;/td&gt;
&lt;td&gt;0.473&lt;/td&gt;
&lt;td&gt;0.474&lt;/td&gt;
&lt;td&gt;0.474&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0.431&lt;/td&gt;
&lt;td&gt;0.435&lt;/td&gt;
&lt;td&gt;0.433&lt;/td&gt;
&lt;td&gt;0.434&lt;/td&gt;
&lt;td&gt;0.434&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;explanation&#34;&gt;Explanation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;By default, both &lt;code&gt;rs.surv()&lt;/code&gt;, &lt;code&gt;stns&lt;/code&gt;, &lt;code&gt;stpp&lt;/code&gt; calculate survival using the product integral method on the hazard level, whereas in &lt;code&gt;strs&lt;/code&gt; and &lt;code&gt;stnet&lt;/code&gt; time-scale is split into numbers of intervals (using actuarial life-table approach).&lt;/li&gt;
&lt;li&gt;In &lt;code&gt;stpp&lt;/code&gt;, the Fleming-Harrington estimator (using the expoential of the negative cumulative (excess) hazard), which appears to be more sensitive to ties, is also eligible to be applied (3).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stnet&lt;/code&gt; should generate the identical estimates as &lt;code&gt;strs&lt;/code&gt;, given that &lt;code&gt;ht&lt;/code&gt; is specified in &lt;code&gt;strs&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Removing ties did not have an effect with discrete time estimators using life-table framework. (&lt;code&gt;strs&lt;/code&gt; and &lt;code&gt;stnet&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;In &lt;code&gt;strs&lt;/code&gt; and &lt;code&gt;stnet&lt;/code&gt;, life-table framework is implemented to estimate relative survival. However, should the cutpoints be in months &lt;code&gt;br(0(`=1/12&#39;)10)&lt;/code&gt; or in years &lt;code&gt;br(0(1)10)&lt;/code&gt;?&lt;br&gt;
A: Monthly estimate is more accurate. Both &lt;code&gt;strs&lt;/code&gt; and &lt;code&gt;stnet&lt;/code&gt; - calculates the attained age and attained year at the beginning  of each interval and takes the &lt;code&gt;floor()&lt;/code&gt; of these values from the popmort file to obtain the expected mortality rate. However, typically the survivaly probility from the popmort file (calculated from 1-year probability of death, by using  by $-exp(H)$) is the probability of surviving 1 year, $p$. If it is monthly interval, we take the twelth root of the survival probability, $p^{1/12}$. Calculating by month literally means we do it 12 times to calculate the survival from an $x$ year-old person until he turns $(x+1)$ years old, but if using annual interval, we do it once instead.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;It is worth paying attention to how age and year are managed in each program.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;stns&lt;/code&gt;: age of dianosis in the cohort data and age in the popmort file are needed in &lt;code&gt;age()&lt;/code&gt;;  year of dianosis &lt;del&gt;date of diagnosis&lt;/del&gt; and the calendar year in the popmort file should be specified in &lt;code&gt;period()&lt;/code&gt; .&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stpp&lt;/code&gt;: age and date of diagnosis should be specified in &lt;code&gt;agediag()&lt;/code&gt; and &lt;code&gt;datediag()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;strs&lt;/code&gt;: age and year of diagnosis are required in &lt;code&gt;diagage()&lt;/code&gt; and &lt;code&gt;diagyear()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stnet&lt;/code&gt;: date of dianosis &lt;code&gt;diagdate()&lt;/code&gt; and date of birth &lt;code&gt;birthdate()&lt;/code&gt; are required.&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Pohar Perme M, Stare J, Estève J. On Estimation in Relative Survival. Biometrics. 2012;68:113-120&lt;/li&gt;
&lt;li&gt;Dickman P, Coviello E. Estimating and modelling relative survival. The Stata Journal. 2015;15:186-215.&lt;/li&gt;
&lt;li&gt;Fleming TR, and Harrington DP. Nonparametric Estimation of the Survival Distribution in Censored Data.Communications in Statistics—Theory and Methods. 1984;13:2469–2486.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;acknowledgement&#34;&gt;Acknowledgement&lt;/h3&gt;
&lt;p&gt;We especially want to say thank-you to 
&lt;a href=&#34;https://pclambert.net&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paul Lambert&lt;/a&gt; for offering his scenario2_1.dta as an example dataset and substantial insights on the syntaxes of &lt;code&gt;stns&lt;/code&gt;and &lt;code&gt;stnet&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Make ratetable using R</title>
      <link>https://enochytchen.com/tutorials/ratetable/otherapp/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/tutorials/ratetable/otherapp/</guid>
      <description>&lt;p&gt;In the last section of this tutorial, we would like to briefly introduce two other approaches for making rate table from a sub-population (Bower et al. 2018, Rachet et al. 2015). First, to summarise these three approaches, we made a comparison chart shown below:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Our approach&lt;/th&gt;
&lt;th&gt;Bower 2018&lt;/th&gt;
&lt;th&gt;Rachet 2015&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Nationwide life table&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;td&gt;v&lt;/td&gt;
&lt;td&gt;Flexible relation model: v Flexible Poisson model: x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Individual data on a reference population&lt;/td&gt;
&lt;td&gt;v&lt;/td&gt;
&lt;td&gt;v&lt;/td&gt;
&lt;td&gt;individual-level or grouped data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dealing with unceratinty&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;td&gt;Parametric bootstrapping&lt;/td&gt;
&lt;td&gt;Using data on multiple sampling populations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Characteristics&lt;/td&gt;
&lt;td&gt;Modelling mortality rates directly without requiring nationwide life table&lt;/td&gt;
&lt;td&gt;Stabilised  by nationwide life table&lt;/td&gt;
&lt;td&gt;Alternative to avoiding integrating the pattern of nationwide life table, but still obtaining robust estimates&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;example-1-adjust-expected-mortality-rate-by-using-adjustment-factor&#34;&gt;Example 1: Adjust expected mortality rate by using adjustment factor&lt;/h3&gt;
&lt;p&gt;
&lt;a href=&#34;https://doi.org/10.1093/aje/kwx303&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bower et al. (2018)&lt;/a&gt;  used the individual-level data from a reference population to scale the expected mortality for each level of social class, aided by nationwide life tables.&lt;/p&gt;
&lt;p&gt;Rather than using the the typical defintion of relative survival ($R(t)$, defined as the ration between $S(t)$, the all-cause survival of a patient cohort and $S^*(t)$, the expected survival of a general population), Bower et al. extended it to estimate the relative survival between the breast cancer patients and the Swedish population, with available data on SES, age at diagnosis, year of diagnosis (in their case, all the breast cancer patients were women, so sex was exempted), shown below:&lt;/p&gt;
&lt;p&gt;$$
R\left(t \mid \mathrm{SES}, a_{d}, y_{d}\right)=\frac{S\left(t \mid \mathrm{SES}, a_{d}, y_{d}\right)}{S^{*}\left(t \mid \mathrm{SES}, a_{d}, y_{d}\right)}
$$&lt;/p&gt;
&lt;p&gt;That is, on hazard scale, the expected hazard (or so-called expected mortality rate) is required to be stratified by SES. Thus, they proposed estimating adjustment factors, $\rho_{j}$, corresponding to SES grops, and multiplied it with the unadjusted rate to generate SES-adjusted mortality rate.
$$
\frac{h_{c}(a, y, j)}{h^{*}(a, y)}=\exp \left[\sum_{j=1}^{3} \rho_{j}(a, y) \times \operatorname{SES}_{j}\right]
$$&lt;/p&gt;
&lt;p&gt;In the article, they further showed that how this framework works using Poisson models and flexible parametric models with restricted cubic spline function. For tackling uncertainty in using a sub-population, they ran a parametric bootstrap method for 100 times.&lt;/p&gt;
&lt;h3 id=&#34;example-2-multivariable-flexible-modelling&#34;&gt;Example 2: Multivariable flexible modelling&lt;/h3&gt;
&lt;p&gt;
&lt;a href=&#34;https://doi.org/10.1186/s12889-015-2534-3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rachet et al. (2015)&lt;/a&gt;  proposed two alternative approaches to construct smoothed life tables for sub-populations. Both these two models can be applied into either abriged or complete data. That is to say, both individual-level data and grouped data can be modelled.&lt;/p&gt;
&lt;h4 id=&#34;flexible-relational-model&#34;&gt;Flexible relational model&lt;/h4&gt;
&lt;p&gt;The first one, flexible relational model, requires survival function of a reliable standard population, $l_{x_{s}}$, and multivariables, such as deprivation level and the interaction between deprivation level and age.&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\operatorname{logit}\left(l_{x, i}\right) &amp;amp;=f\left(\log i t\left(l_{x_{s}}\right)\right) +\sum_{i=2}^{5} \beta_{i} \text {dep}_{i}+g(\text {agedep})
\end{aligned},
$$
where $f$ and $g$ are restricted cubic spline functions.&lt;/p&gt;
&lt;h4 id=&#34;flexible-poisson-model&#34;&gt;Flexible Poisson model&lt;/h4&gt;
&lt;p&gt;The second one, flexible Poisson model, does not require  external infromation on standard population mortality, and it models age-specific death counts with multiple variables.
The advantage is that this approach takes account of the variance existing in the data.&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\log \left(d_{x, i}\right) &amp;amp;=\beta_{0}+f(x)+\sum_{i=2}^{5} \beta_{i} \text {dep}_{i}+g(\text {agedep})+\log \left(\text {pyrs}_{x, i}\right)
\end{aligned},
$$&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Our approach is distinct from Bower et al. and Rachet et al. , since only individual-level data is required to model the mortality rate directly from a representative population free of the disease of interest, the advantages of which are that in some situation nationwide life tables are not available and allowing more variance on the estimates directly generated from the reference population. However, the disadvantage is that the estimates of the model is not aided by the underlying pattern of existing life tables.&lt;/p&gt;
&lt;p&gt;In terms of concerns on uncertainty, Bower et al. used a sensible approach of bootstrapping to tackle the issue, which is eligible to be considered in optimising our approach.&lt;/p&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;p&gt;Bower H, Andersson TM, Crowther MJ, Dickman PW, Lambe M, Lambert PC. Adjusting Expected Mortality Rates Using Information From a Control Population: An Example Using Socioeconomic Status. &lt;em&gt;Am J Epidemiol.&lt;/em&gt; 2018;187(4):828-836. 
&lt;a href=&#34;https://doi.org/10.1093/aje/kwx303&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi: 10.1093/aje/kwx303&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Rachet B, Maringe C, Woods LM, Ellis L, Spika D, Allemani C. Multivariable flexible modelling for estimating complete, smoothed life tables for sub-national populations. &lt;em&gt;BMC Public Health&lt;/em&gt;. 2015;15:1240. 
&lt;a href=&#34;https://doi.org/10.1186/s12889-015-2534-3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi: 10.1186/s12889-015-2534-3&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Thesis Journey at MPH, Epidemiology</title>
      <link>https://enochytchen.com/talk/mphthesis/</link>
      <pubDate>Mon, 31 Aug 2020 11:30:00 +0000</pubDate>
      <guid>https://enochytchen.com/talk/mphthesis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Avoid dehumanizing language use</title>
      <link>https://enochytchen.com/post/avoid_dehumanizing/</link>
      <pubDate>Mon, 24 Aug 2020 10:49:13 +0200</pubDate>
      <guid>https://enochytchen.com/post/avoid_dehumanizing/</guid>
      <description>&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#principles&#34;&gt;Principles&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#reference&#34;&gt;Reference&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;My recent work was on analyzing a patient cohort data. In the syntax documentation, there was one sentence I wrote, &amp;ldquo;We then exacted the birth date of &lt;strong&gt;each observation&lt;/strong&gt;.&amp;rdquo; My colleague then suggested me to use the other term &amp;ldquo;&lt;strong&gt;each individual&lt;/strong&gt;&amp;rdquo; instead. The reason behind his argument is to avoid dehumanizing language. This is such a important component of scientific writing I should have picked up!&lt;/p&gt;
&lt;p&gt;In scientific writing, we aim to pre-conceive ideas about individuals, both the treatment group and the control group, whereas it is essential to use correct languages to describe them. Incorrect, or even poorly selected, words can harm patients. Furthermore, it definitely has negative impact on the relationship between clinicians/researchers and patients. Once trust is broken, it is difficult to regain.&lt;/p&gt;
&lt;p&gt;Leopold S. et al wrote an article, entitled: Editorial: Words Hurt – Avoiding Dehumanizing Language in Orthopaedic Research and Practice (1), offers a holistic viewpoint on using people-first language on scientific writing, especially in biomedicine fields. Here are some priciples I summarized from their publication.&lt;/p&gt;
&lt;h3 id=&#34;principles&#34;&gt;Principles&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Patients are humans. They should be referred to the correct relative pronoun &amp;ldquo;&lt;strong&gt;who&lt;/strong&gt;&amp;rdquo; rather than &amp;ldquo;that&amp;rdquo;.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Patients &lt;del&gt;that&lt;/del&gt; who present for treatment of &amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Make clear that patients are more than their symptoms and diagnoses.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;del&gt;Diabetic patients&lt;/del&gt; Patients with diabetes&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Amputees&lt;/del&gt; Patients who have had amputations&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Evaluate patients&amp;rsquo; self perception. Thus, use correct terms to characterize control groups as well. A value-neutral terminology is preferred. Otherwise, we might in fact implicate insulting the treatment/exposure group.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Using normal/able-bodied individuals to refer to the control individuals. Are we saying that the treatment group is &lt;strong&gt;NOT&lt;/strong&gt; normal/able-bodied.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Being a thoughtful and sensible writer is the milestone of delievering good research language, isn&amp;rsquo;t it?&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Leopold s et al, Editorial: Words Hurt – Avoiding Dehumanizing Language in Orthopaedic Research and Practice. Clin Orthop Relat Res. 2014 Sep; 472(9): 2561–2563. doi: 
&lt;a href=&#34;https://dx.doi.org/10.1007%2Fs11999-014-3802-8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.1007/s11999-014-3802-8&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Make ratetable using R</title>
      <link>https://enochytchen.com/tutorials/ratetable/content/</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/tutorials/ratetable/content/</guid>
      <description>&lt;p&gt;Enoch Chen, Paul Dickman&lt;/p&gt;
&lt;p&gt;The syntax used in this tutorial can be found 
&lt;a href=&#34;https://enochytchen.com/tutorials/ratetable/content/create_ratetable.R&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;data-preparation&#34;&gt;Data preparation&lt;/h3&gt;
&lt;p&gt;Install required packages and read the data. We are using a data set containing information on individuals diagnosed with colon cancer (because the data are publically available). In a real application we would use data on individuals randomly selected from the general population.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; 1 Preparation

#&#39; Clear all
#&#39; Use it if you need to clear all
#&#39; rm(list = ls()) 

#&#39; Load required packages
x&amp;lt;-c(  &amp;quot;haven&amp;quot;,       # read.dta()
       &amp;quot;tidyverse&amp;quot;,   # dplyr::mutate
       &amp;quot;lubridate&amp;quot;,   # decimal_date
       &amp;quot;survival&amp;quot;,    # Surv(), survSplit()
       &amp;quot;rstpm2&amp;quot;,      # stpm2()
       &amp;quot;splines&amp;quot;,     # nsx()
       &amp;quot;relsurv&amp;quot;,     # transrate(), joinrate(), rs.surv()
       &amp;quot;popEpi&amp;quot;,      # as.data.frame(ratetable)
       &amp;quot;ggplot2&amp;quot;)     # ggplot()

lapply(x, require, character.only = TRUE)

#&#39; Read the data from web 
colon &amp;lt;- read_dta( &amp;quot;http://enochytchen.com/directory/data/colon.dta&amp;quot;)
str(colon)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We then created an approximate birth date for each individual by using dx (date of diagnosis) - age at diagnosis * 365.241. The unit here is days in order to be consistent with the unit in &lt;code&gt;relsurv::rs.surv()&lt;/code&gt;. Variables sex, subsite, stage, and strata were converted into factor class, which will be automatically converted into dummy varaibles in a regression model in R. In this example, we used two dimensions: subsite + stage, and combined them into one stratum, a combination of all the dimensions except sex, age, and year. Splitting the data frame into lists will be done on this stratum afterwards.  However, if there is only one extra dimension, it is not required to create a stratum. Instead, it is straightforward to split on that single variable.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; Approximate the date of birth,
#&#39; Will take care of derived variables (entry/exit years) later
colon2 &amp;lt;- colon %&amp;gt;%
  mutate(sex     = as_factor(sex),       ## as_factor preserves labels
         status  = as.numeric(status),
         subsite = as_factor(subsite),   ## as_factor preserves labels
         stage   = as_factor(stage),     ## as_factor preserves labels
         strata  = as_factor(paste(subsite, stage, sep = &amp;quot;, &amp;quot;)), # strata consists all the dimensions
         dob     = as.Date(dx) - age*365.241,
  ) %&amp;gt;%
  select(id, sex, status, subsite, stage, strata, dob, dx, exit, age)
str(colon2)
summary(colon2)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;splitting-the-time&#34;&gt;Splitting the time&lt;/h3&gt;
&lt;p&gt;We split calendar time into 2-year intervals; for our relatively small data set (15000 individuals) 1-year intervals resulted in convergence problems when we modelled mortality in a later step.&lt;/p&gt;
&lt;p&gt;It is worth taking a look at the definition of &lt;code&gt;episode&lt;/code&gt; in &lt;code&gt;survival::survSplit&lt;/code&gt;, where it explains, &amp;ldquo;&lt;code&gt;episode&lt;/code&gt; 1= less than the first cutpoint, 2= between the first and the second.&amp;rdquo; Based on this default setting, we then moved each episode (period) by 2.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#&#39; Split calendar time into 2-year intervals;
#&#39; splitting in 1-year intervals leads to convergence problems later if
#&#39; stpm2 does not have enough events within each time interval
colon_split &amp;lt;- survSplit(Surv(decimal_date(dx), decimal_date(exit), status, type = &amp;quot;mstate&amp;quot;) ~ .,
                         data = colon2, cut = seq(1975, 1995, by = 2),
                         event = &amp;quot;status&amp;quot;, episode = &amp;quot;period&amp;quot;
) %&amp;gt;%
  # changed word &amp;quot;censor&amp;quot; to 0, so to keep it consistent with original definition
  mutate(status = as.numeric(ifelse(as.character(status) == &amp;quot;censor&amp;quot;,
                                    &amp;quot;0&amp;quot;, as.character(status))) )

#&#39; Inspect: select the first 20 to take a look
head(colon_split, 20)

#&#39; For downstream analysis, we want age as primary time scale;
#&#39; Calculate age at entry and age at exit
#&#39; Also, it would be nice to have the period expressed as actual starting year
#&#39; of the time interval; see ?survSplit for its definition
#&#39; (i.e. 1 = before first interval)
colon_split = mutate(colon_split,
                     age_start = tstart - decimal_date(dob),
                     age_stop  = tstop  - decimal_date(dob),
                     period    = 1975 + (period - 2)*2) # *2 for 2-year intervals

#&#39; Save the data for running AIC/BIC test
#&#39; saveRDS(colon_split, &amp;quot;./Data/split_colon.rds&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;flexible-parametric-model&#34;&gt;Flexible parametric model&lt;/h3&gt;
&lt;p&gt;The colon cancer patients&amp;rsquo; data was modelled in multiple time scales, where the primary time scale is attained age calculated from two time points (&lt;code&gt;age_start&lt;/code&gt; and &lt;code&gt;age_stop&lt;/code&gt;), and the secondary is time-split calendar year fitted a natural spline using &lt;code&gt;nsx()&lt;/code&gt; . Time-dependent effect of explanatory varibles was taken into consideration specifying &lt;code&gt;tvc=list()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fpm &amp;lt;- stpm2(Surv(time = age_start, time2 = age_stop, event = status==2) ~
                  sex + nsx(period, df=2) + subsite+ stage, data = colon_split,
             tvc = list(sex=3, period=2), df = 3)
summary(fpm)

#&#39; A nice hazard plot
#&#39; Age-specific hazard by sex, subsite=2, stage =1, 1980
newdata = data.frame(sex = levels(colon2$sex), 
                     subsite = &amp;quot;Descending and sigmoid&amp;quot;, 
                     stage = &amp;quot;Localised&amp;quot;,
                     period = 1980)
newdata
plot(fpm, newdata = newdata[2,,drop=FALSE],
     type = &amp;quot;hazard&amp;quot;, ci = FALSE,
     xlim = c(40,110), xlab = &amp;quot;Attained age (years)&amp;quot;,
     ylim = c(1E-6,100), ylab  = &amp;quot;Hazard (log-scale)&amp;quot;,
     log = &amp;quot;y&amp;quot;, main = &amp;quot;Age-specific log-hazard for subsite=2, stage =1, period 1980, by sex&amp;quot;)
lines(fpm, newdata = newdata[1,,drop=FALSE],
      type = &amp;quot;hazard&amp;quot;, lty = 2, col = &amp;quot;red&amp;quot;)
legend(&amp;quot;topleft&amp;quot;, legend=c(&amp;quot;Female&amp;quot;, &amp;quot;Male&amp;quot;),
       col=c(&amp;quot;black&amp;quot;, &amp;quot;red&amp;quot;), lty=1:2)                   
&lt;/code&gt;&lt;/pre&gt;






  
  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://enochytchen.com/tutorials/ratetable/content/loghazard_hud6a767dbdddc432ae6a3425963d41629_37068_2000x2000_fit_q90_lanczos.jpeg&#34; &gt;


  &lt;img data-src=&#34;https://enochytchen.com/tutorials/ratetable/content/loghazard_hud6a767dbdddc432ae6a3425963d41629_37068_2000x2000_fit_q90_lanczos.jpeg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;683&#34; height=&#34;401&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;predicted-rates-in-a-data-frame&#34;&gt;Predicted rates in a data frame&lt;/h3&gt;
&lt;p&gt;An empty data frame was generated using &lt;code&gt;expand.grid()&lt;/code&gt; stratified by all the dimensions: sex, age_stop (age), period (year), subsite, and stage. The names of the variables must be consistent with which in the flexible parametric model. Then, &lt;code&gt;predict()&lt;/code&gt; was applied to obtain predicted rates (i.e.,survival) in a data frame, similar to the concept in the extrapolation example using &lt;code&gt;predict&lt;/code&gt; in &lt;code&gt;Stata&lt;/code&gt;: 
&lt;a href=&#34;enochytchen.com/tutorials/extrapolation/allcause/article/&#34;&gt;Extrapolating survival (all-cause survival framework)&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;colon_new &amp;lt;- expand.grid(sex = levels(colon2$sex), 
                         subsite = levels(colon2$subsite),
                         stage = levels(colon2$stage),
                         age_stop = 1:110, 
                         period = 1975:1995)

#&#39;Populate the empty data frame with predicted hazards (based on the fitted model)
colon_new$hazard &amp;lt;- predict(fpm, newdata = colon_new, type = &amp;quot;hazard&amp;quot;)

colon_new &amp;lt;- colon_new %&amp;gt;%
  mutate(prob  = exp(-hazard),
         age   = age_stop,   
  ) %&amp;gt;%
  select(sex, subsite, stage, age, period, prob, hazard)
str(colon_new)

#&#39; Take look at the first 20 rows
head(colon_new, 20)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;create-ratetable&#34;&gt;Create ratetable&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Here comes the highlight of this tutorial!&lt;/strong&gt;&lt;br&gt;
The target focuses on how to transform the mortality rate dataframe into to a &lt;code&gt;ratetable&lt;/code&gt; class data, which is required in &lt;code&gt;rs.surv()&lt;/code&gt;.
The subset of the mortality rate data frame, popmort_new, consists of age, sex, period, strata, and prob (survival probability).&lt;/p&gt;
&lt;p&gt;First, we splitted the data frame into lists by the varaible strata (subsite + stage in this example. i.e., all the combinations of the extra dimensions). Second, we splitted the lists by sex, so we are supposed to obtain the lists stratified by both strata and sex.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;spread()&lt;/code&gt; was then applied to transpose the matricies. Afterwards, &lt;code&gt;transrate()&lt;/code&gt;  combined the lists stratified by sex and &lt;code&gt;joinrate()&lt;/code&gt; made the lists stratified by strata into a &lt;code&gt;ratetable&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;popmort_new &amp;lt;- colon_new %&amp;gt;%
  mutate(strata = paste(subsite, stage, sep = &amp;quot;, &amp;quot;),
  )%&amp;gt;%
  select(age, sex, period, strata, prob)

#&#39; transrate() wants two matrices, both age x year, one for men, one for
#&#39; women;  using split() repeatedly to make it work
#&#39; split() converted a data.fram into lists based on the specified variable

#&#39; First, split our popmort file by strata
pm_split = split(popmort_new[, -4], popmort_new$strata)
str(pm_split)

#&#39; Then we split the list again by sex
pm_split = lapply(pm_split, function(x) split(x[, -2], x$sex))
str(pm_split)

#&#39; Using spread + as.matrix to generate the input matrices that transrate()
#&#39; needs
spread_df = function(x)
{
  ret =  spread(x, period, prob)
  rownames(ret) = ret$age - 1 # Drop the age variable
  ret = ret[, -1]
  as.matrix( ret )
}
pm_split = lapply(pm_split, function(x) lapply(x, spread_df ))
str(pm_split)

#&#39; Now do the transrate() for each strar=ta; we get a list of
#&#39; ratetable-objects
pm_split = lapply(pm_split, function(x) transrate(x$Male, x$Female, yearlim = c(1975, 1995)))
str(pm_split)

#&#39; We can directly use the jointable-command on this list
myratetable &amp;lt;- joinrate(pm_split, dim.name=&amp;quot;strata&amp;quot;)
str(myratetable)

#&#39; Check whether is a readable ratetable for rs.surv()
is.ratetable(myratetable) 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;use-rssurv-to-estimate-net-survival&#34;&gt;Use rs.surv() to estimate net survival&lt;/h3&gt;
&lt;p&gt;It is important to keep in mind that in &lt;code&gt;relsuv::rs.surv()&lt;/code&gt; the unit of follow-up time is specified in days (1). Thus, given that the time in the original colon dataset is in years, we need to multiply the time by 365.241. The same rule applies to age, where in &lt;code&gt;relsuv::rs.surv()::rmap&lt;/code&gt; age should be multiplied by 365.241 as well.
The rate table was generated from this patient data. Therefore, if we estimate net survival using the same data, we should get relative survival close to 1, shown in the following syntax and graph.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rssurv&amp;lt;-rs.surv(Surv(time  =  (decimal_date(exit)-  decimal_date(dx)) * 365.241,
                     event = status == 2) ~
                  sex  + subsite+ stage,                     
                rmap = list(age = age*365.241, year = dx, strata = strata),
                ratetable = myratetable,
                data = colon2,
                method = &amp;quot;ederer2&amp;quot;)

rssurv.sum &amp;lt;- summary(rssurv, time = c(0:10) * 365.241, scale = 365.241)
rs.table   &amp;lt;- as.data.frame(rssurv.sum[c(&amp;quot;strata&amp;quot;, &amp;quot;time&amp;quot;, &amp;quot;n.risk&amp;quot;, &amp;quot;n.event&amp;quot;, &amp;quot;surv&amp;quot;, &amp;quot;std.err&amp;quot;, &amp;quot;lower&amp;quot;, &amp;quot;upper&amp;quot;)])

#&#39; Cut the value from the strata
#&#39; We split the strata to get variables
rs.table_temp &amp;lt;- data.frame(do.call(rbind, 
                                    strsplit(as.character(strsplit(as.character(rs.table$strata), &amp;quot;,&amp;quot;)),&amp;quot;=&amp;quot;, fixed=TRUE)
))

rs.table_temp &amp;lt;- rs.table_temp %&amp;gt;%
  mutate(sex        = substr(X2,1,1),
         subsite2   = substr(X3,1,1),
         subsite3   = substr(X4,1,1), 
         subsite4   = substr(X5,1,1),
         Localised  = substr(X6,1,1),
         Regional   = substr(X7,1,1),
         Distant    = substr(X8,1,1),
  )%&amp;gt;% 
  select(sex, subsite2, subsite3, subsite4, Localised, Regional, Distant)

rs.table &amp;lt;- cbind(rs.table[ ,-c(1, 9)], rs.table_temp)

#&#39; Take a look
#&#39; surv here is cumulative relative survival 
head(rs.table, 20)

# Make plotdata for subsite=2 and Localised=1
rssurv.plotdata &amp;lt;- subset( rs.table, (subsite2 == 1 &amp;amp; Localised ==1) )
summary(rssurv.plotdata)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;plot-net-survival&#34;&gt;Plot net survival&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt; ggplot(rssurv.plotdata, aes(x = time, y = surv, color = sex, fill = sex )) +
  geom_smooth(alpha = 0.25) +   
  scale_x_continuous(breaks = seq(0, 10, by = 2), limits = c(0,10))+
  scale_y_continuous(breaks = seq(0, 1.2, by = 0.2), limits = c(0,1.2))+
  labs(title=&amp;quot;Cumulative relative survival for subsite=2 &amp;amp; stage =localised&amp;quot;,
       x=&amp;quot;Time since diagnosis (years)&amp;quot;, 
       y=&amp;quot;Cumulative relative survival&amp;quot;) +
  theme(plot.title = element_text(size = 10))
&lt;/code&gt;&lt;/pre&gt;






  
  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://enochytchen.com/tutorials/ratetable/content/ggplot_hud6a767dbdddc432ae6a3425963d41629_41383_2000x2000_fit_q90_lanczos.jpeg&#34; &gt;


  &lt;img data-src=&#34;https://enochytchen.com/tutorials/ratetable/content/ggplot_hud6a767dbdddc432ae6a3425963d41629_41383_2000x2000_fit_q90_lanczos.jpeg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;683&#34; height=&#34;401&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Perme, MP, Pavlic, K. Nonparametric relative survival analysis with the R package relsurv. Journal of Statistical Software. 2018; 87(1), 1-27..&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;appendix-codebook&#34;&gt;Appendix: codebook&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;sex: 1 (Male)
2 (Female)&lt;/li&gt;
&lt;li&gt;stage: 0 (Unknown);
1 (Localised);
2 (Regional);
3(Distant)&lt;/li&gt;
&lt;li&gt;subsite: 1(Coecum and ascending);
2 (Transverse);
3 (Descending and sigmoid);
4 (Other and NOS)&lt;/li&gt;
&lt;li&gt;staus: 0 (Alive);
1 (dead from colon cancer);
2 (dead from other causes)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Seven tips of good data management</title>
      <link>https://enochytchen.com/post/gooddatamanagement/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/post/gooddatamanagement/</guid>
      <description>&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#reference&#34;&gt;Reference&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;p&gt;I was pretty inspired by 
&lt;a href=&#34;https://staff.ki.se/people/annajo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Anna Johansson&lt;/a&gt;&amp;rsquo;s 
&lt;a href=&#34;%28https://play.ki.se/media/Data&amp;#43;Management&amp;#43;and&amp;#43;research&amp;#43;documentation&amp;#43;for&amp;#43;researchers/0_h64ki6v7?_ga=2.131118287.1557257458.1589785892-1364153581.1557067020%29&#34;&gt;workshop&lt;/a&gt; and course in good data management at Karolinska Institutet. Thus, I would like to share my experience along with my course notes in this blogpost. For the importance of good data management and my poor experience, please refer to my previous post: 
&lt;a href=&#34;http://enochytchen.com/post/why_datamanaegment/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Data management? Does it matter?&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;tip-1-use-a-shared-drive&#34;&gt;Tip 1: Use a shared drive&lt;/h4&gt;
&lt;p&gt;Spilling coffee on the laptop! The laptop was stolen! These kinds of poor stories we propbably have ever heard from someone else, or they even happened to us. &lt;br&gt; Tragedies could happen, but using a shared drive could lower the impact it brings. Github, Tortoise, or other shared drives with a version control function can save you from the accident. It is recommended to commit your files to the shared drive once you finish the work everyday. Thus, you can always own a previous version of your files at the cloud drive or your colleagues&amp;rsquo;s drive (if they happen to use the same shared drive).&lt;br&gt;
You &lt;strong&gt;commit&lt;/strong&gt; to your job. Why don&amp;rsquo;t you &lt;strong&gt;commit&lt;/strong&gt; your files as well? Establish a good habit of version control.&lt;/p&gt;
&lt;h4 id=&#34;tip-2-give-appropriate-names-to-your-files-and-variables&#34;&gt;Tip 2: Give appropriate names to your files and variables&lt;/h4&gt;
&lt;p&gt;Have you ever given your file an inappropriate name, and then you no longer found it?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Don&amp;rsquo;t use stupid names, such as new1, new2, new3&amp;hellip;final1, final2, final3&amp;hellip;latest1&amp;hellip;&amp;hellip;A simple version mark plus date is quite enough (I usually use yyyymmdd)! E.g., manuscript_v1_20200501.&lt;/li&gt;
&lt;li&gt;No space in-between &amp;amp; No special character, such as Swedish vowels (ä, ö, å) or Mandarin words (請避免使用中文字). This is just to avoid that your file name is not readable to the software.&lt;/li&gt;
&lt;li&gt;For binomial variables, &lt;strong&gt;=1&lt;/strong&gt; implies yes, and &lt;strong&gt;=0&lt;/strong&gt; implies no. E.g., if a variable is entitled as &lt;code&gt;female&lt;/code&gt;, then &lt;strong&gt;=1&lt;/strong&gt; indicates female, &lt;strong&gt;=0&lt;/strong&gt; indicates male.&lt;/li&gt;
&lt;li&gt;Convert a string variable to a numeric variable. Numeric varaibles are usually preferable for doing analysis. For example, in Stata, the conversion is done by &lt;code&gt;destring (variable), replace&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;tip-3-give-the-same-names-for-linking-files&#34;&gt;Tip 3: Give the same names for linking files&lt;/h4&gt;
&lt;p&gt;If you happen to organize the data, generate the log of the syntax, then output the result in word, it is recommended to use an identical name throughout these different files (.do .r .sas  → .log → .doc). The priciple here is simply mark these files were basicaly processed in a series.&lt;/p&gt;
&lt;h4 id=&#34;tip-4-dont-replace-the-original-files-vaiables-if-a-new-one-is-created&#34;&gt;Tip 4: Don&amp;rsquo;t replace the original files/ vaiables if a new one is created&lt;/h4&gt;
&lt;p&gt;It is quite common that new varivables are created during the data analysis. You should only create a new variable rather than overwrite the original variable. For example, &lt;code&gt;age → nage &lt;/code&gt;. The same concept applies if you want to modify a file. However, if you accidentally overwrite the orginal file and you do have version control (&lt;strong&gt;Tip 1&lt;/strong&gt;), there is still chance to trace it back.&lt;/p&gt;
&lt;h4 id=&#34;tip-5-use-file-headers-to-document-your-work&#34;&gt;Tip 5: Use file headers to document your work&lt;/h4&gt;
&lt;p&gt;A file header plays a role as a reminder of what has been done in this single file. It allows us to understand that file by just reading the header. You yourself and your team members definitely say thank-you for keeping this record in the future.
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./fileheader.png&#34; &gt;


  &lt;img src=&#34;./fileheader.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;tip-6-write-notes-while-writing-the-codes&#34;&gt;Tip 6: Write notes while writing the codes&lt;/h4&gt;
&lt;p&gt;My biostat teacher used to talk to himself while writing codes on his program file. He even wrote, &lt;code&gt;What are we doing now? We are gonna......&lt;/code&gt; I actually thought it was quite funny when he did that. But basically, telling yourself what you are doing is quite fundamental, since you &lt;strong&gt;will absolutely forget&lt;/strong&gt; what you did. In addition, when I use new commands, I would also write down what it means, even though at that moment I caught the meaning of it.
The same concept applies to keeping workbook or a working records. Believe me or not, your memories are not trustworthy! It is extra work definitely. Please do write something down and properly keep it.&lt;/p&gt;
&lt;h4 id=&#34;tip-7-write-a-readmetxt&#34;&gt;Tip 7: Write a Readme.txt&lt;/h4&gt;
&lt;p&gt;A Readme.txt functions as a table of contents. Basically, Readme should explain the contents in each folder, the author(s) of the work, and the modification that has been updated.&lt;/p&gt;
&lt;p&gt;Imagine that you go to a restaurant, and you would like to order some dishes. Reasonably, you would ask for a &lt;strong&gt;menu&lt;/strong&gt;. A Readme.txt is the &lt;strong&gt;menu&lt;/strong&gt; of your folders or files. To be a good restaurant owner, would you run your business without a proper &lt;strong&gt;menu&lt;/strong&gt;?&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The Department of Medical Epidemiology and Biostatistics, Karolinska Institutet. MEB Guidelines for Documentation and Archiving Version 6. 2018.&lt;/li&gt;
&lt;li&gt;Johansson A. 
&lt;a href=&#34;https://play.ki.se/media/Data&amp;#43;Management&amp;#43;and&amp;#43;research&amp;#43;documentation&amp;#43;for&amp;#43;researchers/0_h64ki6v7?_ga=2.131118287.1557257458.1589785892-1364153581.1557067020&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Data Management and research documentation for researchers&lt;/a&gt;. KIB Workshop 2018.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Data management? Does it matter?</title>
      <link>https://enochytchen.com/post/why_datamanagement/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/post/why_datamanagement/</guid>
      <description>&lt;h3 id=&#34;why-should-you-do-data-management&#34;&gt;Why should you do data management?&lt;/h3&gt;
&lt;p&gt;We all have experienced unexpected shutdown of our laptops or even files we were still processing and haven&amp;rsquo;t saved yet. Maybe these nightmares are quite unavoidable sometimes; otherwise, I wouldn&amp;rsquo;t call it &lt;strong&gt;unexpected&lt;/strong&gt;, and we would not have &lt;strong&gt;cursed&lt;/strong&gt; as it happened.&lt;/p&gt;
&lt;p&gt;The most attractive points of data management are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;To reproduce your work on analysis.&lt;/strong&gt;
&lt;br&gt;Science is something that could be reproducible, so is &lt;strong&gt;DATA SCIENCE&lt;/strong&gt;. Even though you might not work in a data-driven field, you definitely want to trace back your file records at a point.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;To work coherently and efficiently with yourself&lt;/strong&gt; &lt;br&gt;We all tend to forget where and how we put the files someday. Data management saves you a great amount of time of suffering from getting lost in the mess.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;To help your colleagues to understand the analysis&lt;/strong&gt; &lt;br&gt;It is quite common that if you work in a team, and someone joins after the project has already started, he or she needs to take over a part of the tasks. Then a good data managment gives that new colleague a big picture of what has been completed and what needs to be fixed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;To enhance accuracy of work&lt;/strong&gt;
&lt;br&gt; A good data management leads to a well-structured folders/file/codes/documents. Once any problem happens, it is easier to break down the error and find the bug.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;my-experience-in-poor-data-management&#34;&gt;My experience in poor data management&lt;/h3&gt;
&lt;p&gt;Looking back my experience in managing data, I made a bunch of mistakes, which definitely annoyed my colleagues and stumbled myself. I don&amp;rsquo;t mind writing these bad examples down to highlight the importance of good data managment.&lt;/p&gt;
&lt;h4 id=&#34;project-died-on-the-way&#34;&gt;Project died on the way&lt;/h4&gt;
&lt;p&gt;I was once working in a project entitled &amp;ldquo;Enterovirus epidemic and class suspension in Taiwan&amp;rdquo;. That was the very first time that I had the access into governmental data. Without any analysis plan, I only used the cloud drive to keep the records of data analyses, which were also incomplete, with my supervisor. However, at the end, I was not able to continue the project and publish the results, so my supervisor took over the work. But when he asked me what we did together in the analyses and what extra work I managed to conduct on my own, I couldn&amp;rsquo;t properly answer the questions he proposed, because I did not have an analysis plan! All the data was carried out in an aggregation form, which indicated that we were unable to trace back to the working records in the data&amp;hellip;&amp;hellip;&lt;strong&gt;If I had learned data managment earlier, the project wouldn&amp;rsquo;t have to be halted.&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;my-colleagues-got-mad&#34;&gt;My colleagues got mad&lt;/h4&gt;
&lt;p&gt;The other experience also happened durign my undergrad. I was an NGO intern involved in dengue surveillance project in Northern Malawi. The project took much longer than we expected, so the next year&amp;rsquo;s interns also needed to participate in the unfinished project. However, we were the investigators at the first place. We understood all the project from the very beginning, but they did not. It took effort to explain what we had finished. At the end, even though we had quited the work, those next-years still did not catch the full results and working process of the project. And as I understood, they were not quite happy about the transition of the project. &lt;strong&gt;If I had learned data managment earlier, I would have had better transition of our work.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;solution-good-data-management&#34;&gt;Solution: good data management&lt;/h3&gt;
&lt;p&gt;I picked up good data managment while working as a master thesis student at the Department of Medical Biostatistics and Epidemiology. I benefitted from the 
&lt;a href=&#34;https://play.ki.se/media/Data&amp;#43;Management&amp;#43;and&amp;#43;research&amp;#43;documentation&amp;#43;for&amp;#43;researchers/0_h64ki6v7?_ga=2.131118287.1557257458.1589785892-1364153581.1557067020&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;good data management workshop&lt;/a&gt; and courses offered by 
&lt;a href=&#34;https://staff.ki.se/people/annajo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Anna Johansson&lt;/a&gt; and the data management group. I am quite sure given good data management, those two stories would not have occurred! Isn&amp;rsquo;t that a good news!?&lt;/p&gt;
&lt;p&gt;Do you have the same issure in your data management? Then you should learn 
&lt;a href=&#34;http://enochytchen.com/post/7tips_gooddatamanaegment/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Seven tips of good data management&lt;/a&gt; together.&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Johansson A. 
&lt;a href=&#34;https://play.ki.se/media/Data&amp;#43;Management&amp;#43;and&amp;#43;research&amp;#43;documentation&amp;#43;for&amp;#43;researchers/0_h64ki6v7?_ga=2.131118287.1557257458.1589785892-1364153581.1557067020&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Data Management and research documentation for researchers&lt;/a&gt;. KIB Workshop 2018.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Not easy to be a fortune teller: prediction is hard</title>
      <link>https://enochytchen.com/post/prediction/</link>
      <pubDate>Tue, 12 May 2020 14:52:16 +0200</pubDate>
      <guid>https://enochytchen.com/post/prediction/</guid>
      <description>&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#the-uks-life-expectancy-projection&#34;&gt;The UK&amp;rsquo;s life expectancy projection&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#the-swedens-life-expectancy-projection&#34;&gt;The Sweden&amp;rsquo;s life expectancy projection&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#reflection&#34;&gt;Reflection&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#reference&#34;&gt;Reference&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;p&gt;There are a bunch of quotes related to prediction which can be found at

&lt;a href=&#34;https://quoteinvestigator.com/2013/10/20/no-predict/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;It’s Difficult to Make Predictions, Especially About the Future&lt;/a&gt;. Basically, these quotes do not differ from one another. They generally want to express that predection on future is risky and chanllenging. Moreover, it could lead to quantitative problems, such as underestimation or overestimation.&lt;/p&gt;
&lt;p&gt;Recently, while I was working on life expectancy estimation, a colleague proposed a quesiton, &amp;ldquo;If you are validating expected survival of patients in 1990s, shall you use the survival projection made in 1990s rather than the empircal survival?&amp;rdquo; As a person living in 2020, it was quite intuitive to me to use empirical data to validate the survival prediction. Nevertheless, practically, statisticians back to 1990s only had projection data. Based on this fact, I was quite convinced that I should have used the projection data made at that time.&lt;/p&gt;
&lt;p&gt;However, how precise was the data? Here come two small examples of validating life expectancy projection in the UK and Sweden.&lt;/p&gt;
&lt;h3 id=&#34;the-uks-life-expectancy-projection&#34;&gt;The UK&amp;rsquo;s life expectancy projection&lt;/h3&gt;
&lt;p&gt;The UK&amp;rsquo;s Office for National Statistics has ever published a report of validating the accurancy of life expectancy. The following figure was downloaded from 
&lt;a href=&#34;https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationprojections/methodologies/nationalpopulationprojectionsaccuracyreport&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;National Population Projections Accuracy Report&lt;/a&gt; (1).&lt;/p&gt;
















&lt;figure id=&#34;figure-actual-and-projected-life-expectancy-at-birth-uk-1966-2030&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./uk_LEprojection.png&#34; data-caption=&#34;Actual and projected life expectancy at birth, UK, 1966-2030&#34;&gt;


  &lt;img src=&#34;./uk_LEprojection.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Actual and projected life expectancy at birth, UK, 1966-2030
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;It seems that the projection made before 2002 did not perform quite well. For example, projection made in 1975 saying males&amp;rsquo; life expectancy at birth was estimated to be 71 in 2001, whereas in 2001 it was actuall 79. A 8 years of difference! Then let&amp;rsquo;s take a look on the Swedish population.&lt;/p&gt;
&lt;h3 id=&#34;the-swedens-life-expectancy-projection&#34;&gt;The Sweden&amp;rsquo;s life expectancy projection&lt;/h3&gt;
&lt;p&gt;Statistiska centralbyrån (Statistics Sweden) also published a similar report as the UK did to evaluate their previous projection on life expectancy. The following figure was downloaded from 
&lt;a href=&#34;http://share.scb.se/ov9993/data/publikationer/statistik/_publikationer/be0401_2012i60_br_be51br1202.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sveriges framtida befolkning 2012–2060&lt;/a&gt;(2).&lt;/p&gt;
















&lt;figure id=&#34;figure-actual-and-projected-life-expectancy-at-birth-sweden-1950-2012&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./se_LEprojection.png&#34; data-caption=&#34;Actual and projected life expectancy at birth, Sweden, 1950-2012&#34;&gt;


  &lt;img src=&#34;./se_LEprojection.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Actual and projected life expectancy at birth, Sweden, 1950-2012
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The similar issue happened here as well. Earlier projection (before 2000) was not quite right in comparison with the empirical one.&lt;/p&gt;
&lt;p&gt;This report was done in 2012 (the empirical trend until 2012). I then followed what Statistics Sweden conducted to generate a similar graph with the earliest open-access projection data till 2009 and empirical data till 2018 using data from Statistics Sweden (3) as well.&lt;/p&gt;
















&lt;figure id=&#34;figure-actual-and-projected-life-expectancy-at-birth-sweden-2000-2030&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./LEprojection_validation_SE_2030.jpg&#34; data-caption=&#34;Actual and projected life expectancy at birth, Sweden, 2000-2030.&#34;&gt;


  &lt;img src=&#34;./LEprojection_validation_SE_2030.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Actual and projected life expectancy at birth, Sweden, 2000-2030.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The difference was not as large as projection before 2000, but still, there could be 1-2 years of difference if projecting to 2030.&lt;/p&gt;
&lt;h3 id=&#34;reflection&#34;&gt;Reflection&lt;/h3&gt;
&lt;p&gt;The validation between the empirical and the projection makes me aware that the longer we predict, the more potential bias may happen as well. This is just an example of why projection into the future could be adventurous. Imagine that if it is already uncertain in life expectancy prediction of the general population, would it be more difficult to predict a group of people&amp;rsquo;s (such as a patient cohort&amp;rsquo;s) survival? For sure, I would pretty much say yes because multiple factors can all contribute to the change of that specific group of people, like advancement of treatment, geographical difference, healthcare delievery, etc.&lt;/p&gt;
&lt;p&gt;Then shall we give up projection? I would however say no. I believe making prediction on something is better than knowing nothing and going ahead, even though people can always argue that we are forecasting &lt;strong&gt;the future&lt;/strong&gt; and say, &amp;ldquo;You never know.&amp;rdquo; Well, at least having a reference point is better than none, isn&amp;rsquo;t it? Still, I agree that there is no perfect prediction. Who knows what is happening tomorrow? However, prediction made diligently is more believable than casually forecasting the future.&lt;/p&gt;
&lt;p&gt;Doesn&amp;rsquo;t my job sound like a fortune teller?&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Office for National Statistics, UK. National Population Projections Accuracy Report, 2015. Available from:
&lt;a href=&#34;https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationprojections/methodologies/nationalpopulationprojectionsaccuracyreport&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.ons.gov.uk/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Statistiska centralbyrån (Statistics Sweden). Sveriges framtida befolkning 2012–2060 (Sweden&amp;rsquo;s future population), 2012. Available from 
&lt;a href=&#34;http://share.scb.se/ov9993/data/publikationer/statistik/_publikationer/be0401_2012i60_br_be51br1202.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://share.scb.se/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Statistiska centralbyrån (Statistics Sweden). Statistical database: Earlier projections on life expectancy by sex and age. Available from: &lt;a href=&#34;http://www.statistikdatabasen.scb.se/pxweb/en/ssd/&#34;&gt;http://www.statistikdatabasen.scb.se/pxweb/en/ssd/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Extrapolating survival (all-cause survival framework)</title>
      <link>https://enochytchen.com/tutorials/extrapolation/allcause/article/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/tutorials/extrapolation/allcause/article/</guid>
      <description>&lt;p&gt;The codes used in this post are available 
&lt;a href=&#34;http://enochytchen.com/directory/stata/extrapolating_allcause_stpm2.do&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This blogpost introduces how to extrapolate patients&amp;rsquo; survival using flexible parametric model with age groups (categorical variable) as covariates. The tutorial is following the post 
&lt;a href=&#34;http://pauldickman.com/software/stata/prediction_new_data/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Predicting in a new data set with stpm2&lt;/a&gt; from 
&lt;a href=&#34;http://pauldickman.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paul Dickman&lt;/a&gt;&amp;rsquo;s website, where he introduced how to extrapolate all-cause survival using flexible parametric model with age (continuous variable) and sex.&lt;/p&gt;
&lt;p&gt;The following extrapolation results can then answer questions such as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is the estimated survival of patients aged 50-59 diagnosed with colon cancer during 1975-1985?&lt;/li&gt;
&lt;li&gt;What is the estimated survival of patients aged &amp;lt;50 diagnosed with breast cancer during 2000-2010?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data-preparation&#34;&gt;Data preparation&lt;/h4&gt;
&lt;p&gt;First you need to prepare the data before start modeling with stpm2. The exmaple colon cancer data used here can be found from my 
&lt;a href=&#34;https://enochytchen.com/tutorials/extrapolation/data_prep/data_preparation/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;previous post: Data preparation&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;use colon1975_1985,clear
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;stset stime, failure(dead==1,2) id(id) exit(time 10) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We stset the data for survival analysis. In this dataset, death from cancer was coded as dead=1 and from other causes as dead=2. We are interested in patients who died from any cause. We then assumed the maximum follow-up was 10 years, so exit(time 10) was set for making everyone censored after 10 years.&lt;/p&gt;
&lt;h4 id=&#34;modeling-with-stpm2&#34;&gt;Modeling with &lt;code&gt;stpm2&lt;/code&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;stpm2 agegroup2-agegroup5, /// agegroup0 is reference group
scale(hazard) df(5) eform /// hazard: propotional hazard
tvc(agegroup2-agegroup5) dftvc(2) // tvc allows non-proportional hazard
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We then modeled the survival data in the flexible parametric model using stpm2. Basically, the setting showed that it is a proportional hazard model using scale(hazard), but we allowed time-dependent effects on the age group by using tvc(agegroup2-agegroup5).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;clear
range agegroup 0 4 5 
range _t 0 20 241 // (12*20)+1=241
fillin agegroup _t
drop if missing(agegroup,_t)

quietly tab agegroup, gen(agegroup)
 
predict s, survival timevar(_t) 
sort agegroup _t

save colon1975_1985_10yr_extrap, replace
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As the model was stored in the background, we first cleared the data but created a new dataset (12 months*20years + the last point) for prediction by using &lt;code&gt;fillin&lt;/code&gt;
function. We then predict the survival by age group using predict to gain extrapolated values beyond 10 year of follow-up.&lt;/p&gt;
















&lt;figure id=&#34;figure-extrapolation-by-restricting-follow-up-data-to-10-years&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./extrap_allcause_fig1.png&#34; data-caption=&#34;Extrapolation by restricting follow-up data to 10 years&#34;&gt;


  &lt;img src=&#34;./extrap_allcause_fig1.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Extrapolation by restricting follow-up data to 10 years
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The survival was by age groups, where the first 10 years were observed survival and later came the predicted survival.&lt;/p&gt;
















&lt;figure id=&#34;figure-comparing-extrapolation-with-empirical-k-m-curve&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./extrap_allcause_fig2.png&#34; data-caption=&#34;Comparing extrapolation with empirical K-M curve&#34;&gt;


  &lt;img src=&#34;./extrap_allcause_fig2.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Comparing extrapolation with empirical K-M curve
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;To evaluate the extrapolated survival, we then compared it with the empirical survival estimated by the Kaplan-Meier&amp;rsquo;s (K-M) method.&lt;/p&gt;
&lt;p&gt;It seemed that for certain age groups in this dataset, the extrapolation would deviate from the empirical K-M curve. To obtain robust prediction, we prefer borrowing external information, such as vital statistics, to extrapolate the survival in relative survival framework rather than all-cause survival. Please refer to the next post: 
&lt;a href=&#34;http://enochytchen.com/tutorials/extrapolation/relative/extrapolating_rel/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt; Extrapolating survival (relative survival framework) &lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Data clearance</title>
      <link>https://enochytchen.com/tutorials/extrapolation/data_prep/data_preparation/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/tutorials/extrapolation/data_prep/data_preparation/</guid>
      <description>&lt;p&gt;The codes used in this post are available 
&lt;a href=&#34;http://enochytchen.com/directory/stata/data_prep_extrapolation.do&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;// This data was downlaoded from Paul Dickman&#39;s website

// Diagnosis 1975-1985
use http://enochytchen.com/directory/data/colon.dta if yydx&amp;gt;=1975 &amp;amp; yydx&amp;lt;=1985, clear
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data is originally from &lt;a href=&#34;https://pauldickman.com/survival/colon.dta,&#34;&gt;https://pauldickman.com/survival/colon.dta,&lt;/a&gt; permited use by 
&lt;a href=&#34;http://pauldickman.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paul Dickman&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;// Rename variables
rename yydx yeardiag
rename age agediag
gen stime=surv_mm/12
rename status dead
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The varaibles are renamed for further use in the upcoming analysis.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Smart way to creating age groups
egen agegroup=cut(agediag), at(0 50 60 70 80 200) icodes
label variable agegroup &amp;quot;Age group&amp;quot;
label define agegroup 0 &amp;quot;0-49&amp;quot; 1 &amp;quot;50-59&amp;quot; 2 &amp;quot;60-69&amp;quot; 3 &amp;quot;70-79&amp;quot; 4 &amp;quot;80+&amp;quot; 
label values agegroup agegroup
// Create dummy varaiables for age categories
quietly tab agegroup, gen(agegroup)

save colon1975_1985,replace
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Patients were categorized by age group &amp;lt;50, 50-59, 60-69, 70-79, &amp;gt;=80. Dummy variables on age group were created for modeling in stpm2. Then save the file for further modeling.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Make expected survival</title>
      <link>https://enochytchen.com/tutorials/extrapolation/relative/make_expected_survival/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/tutorials/extrapolation/relative/make_expected_survival/</guid>
      <description>&lt;p&gt;The codes used in this post are available 
&lt;a href=&#34;http://enochytchen.com/directory/stata/make_expected_survival.do&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Extrapolating survival (relative survival framework)</title>
      <link>https://enochytchen.com/tutorials/extrapolation/relative/article/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/tutorials/extrapolation/relative/article/</guid>
      <description>&lt;p&gt;The codes used in this post are available 
&lt;a href=&#34;http://enochytchen.com/directory/stata/extrapolating_relative_stpm2.do&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;data-preparation&#34;&gt;Data preparation&lt;/h4&gt;
&lt;p&gt;First you need to prepare the data before start modeling with stpm2. The exmaple data used here can be found from my 
&lt;a href=&#34;https://http://enochytchen.com/tutorials/extrapolation/data_prep/data_preparation/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;previous post: Data preparation&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;expected-survival&#34;&gt;Expected survival&lt;/h4&gt;
&lt;p&gt;Other than modeling on patient survival, $S(t)$, it is more plausible to borrow external information, such as vital statistics, to obtain expected survival, $S^{*}(t)$, to extrapolate survival within relative survival framework.&lt;/p&gt;
&lt;p&gt;$R(t)=\frac{S(t)}{S^{*}(t)}$&lt;/p&gt;
&lt;p&gt;The analogue of relative survival, $R(t)$,  on a hazard scale is&lt;/p&gt;
&lt;p&gt;$h(t)=h^{*}(t)+\lambda(t)$&lt;/p&gt;
&lt;p&gt;By integration, the result is&lt;/p&gt;
&lt;p&gt;$H(t)=H^{*}(t)+\Lambda(t),$&lt;/p&gt;
&lt;p&gt;where the cumulative hazard, $H(t)$, consists of the cumulative expected hazard, $H^{*}(t)$, and the cumulative excess hazard, $\Lambda(t)$.&lt;/p&gt;
&lt;p&gt;The cumulative expected hazard can be obtained from population mortality. For how to prepare life table data for expected survival, the hand-in-hand teaching materials can be found at my previous posts: 
&lt;a href=&#34;https://http://enochytchen.com/tutorials/extrapolation/data_prep/popmort_projection/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Population mortality rate projection&lt;/a&gt; and 
&lt;a href=&#34;https://http://enochytchen.com/tutorials/extrapolation/extrapolating_rel/make_expected_survival/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prepare expected survival&lt;/a&gt;. colon_expected_survival.dta and popmort_projection.dta, both of which will be used in the following modeling process, will be generated after running the do files.&lt;/p&gt;
&lt;p&gt;After running the above programs, we then acquire the expected survival corresponding to the patient cohort&amp;rsquo;s survival by age, sex, and calendar year. Here we start model the relative survival.&lt;/p&gt;
&lt;h4 id=&#34;creating-relative-survival&#34;&gt;Creating relative survival&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;use colon1975_1985,clear
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;stset stime, failure(dead==1,2) id(id) exit(time 10) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We stset the data for survival analysis. In this dataset, death from cancer was coded as dead=1 and from other causes as dead=2. We are interested in patients who died from any cause. We then assumed the maximum follow-up was 10 years, so exit(time 10) was set for making everyone censored after 10 years.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gen _year= floor(min(yeardiag + _t, 1995)) 
gen _age=floor(min(agediag + _t, 105)) 

merge m:1 _year sex _age /// 
	using popmort_projection.dta, ///
	nolabel keep(match master) keepusing(rate) 
	
drop _age _year _merge
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;_year and _age were created corresponding to the life table. The maximum of _year was set as 1995, and _age as 105. Then the patients&amp;rsquo; survival data was merged with life table to obtain the expected mortality rate.&lt;/p&gt;
&lt;h4 id=&#34;modeling-relative-survival-with-stpm2&#34;&gt;Modeling relative survival with &lt;code&gt;stpm2&lt;/code&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;stpm2 agegroup2-agegroup5, ///
scale(hazard) df(5) eform ///
tvc(agegroup2-agegroup5) dftvc(2) bhazard(rate) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Rather than 
&lt;a href=&#34;http://enochytchen.com/tutorials/extrapolation/allcause/extrapolating_all/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;modeling all-cause survival&lt;/a&gt;, we specified using bhazard(rate) for modeling relative survival on log cumulative excess hazard using stpm2.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;clear
range agegroup 0 4 5 
range _t 0 20 241 // (12*20)+1=241
fillin agegroup _t
drop if missing(agegroup,_t)

quietly tab agegroup, gen(agegroup)

predict rs, survival timevar(_t) 
sort agegroup _t

save colon_10yr_rs_extrap, replace
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Still a empty dataset was created for extrapolation. We then predict the &lt;strong&gt;relative survival&lt;/strong&gt; by age group using predict to gain extrapolated values beyond 10 year of follow-up and save the extrapolated relative survival.&lt;/p&gt;
&lt;p&gt;So far we have already successfully predicted relative survival. Looking back to the equation of relative survival, R(t), it can be easily transformed back to the all-cause survival, $S(t)$, by multiplying with expected survival, $S^*(t)$.&lt;/p&gt;
&lt;p&gt;$S(t)=R(t) \times S^{*}(t)$&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;use colon_expected_survival, clear
sort agegroup _t

merge m:1 agegroup _t  ///
using  colon_10yr_rs_extrap, ///
nolabel keep(match master) keepusing(rs) 

//S(t)=S^*(t) * R(t)
//cp=cp_e2*cr_e2
drop _merge
gen obs=cp_e2*rs
replace obs=1 if _t==0
sort agegroup _t

save colon_10yr_rs_to_allcause, replace
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;





  
  











&lt;figure id=&#34;figure-extrapolation-by-restricting-follow-up-data-to-10-years&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://enochytchen.com/tutorials/extrapolation/relative/article/extrap_rel_fig1_hu563a6fc5b07ca74af1cf00cd17cdbc8c_108321_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Extrapolation by restricting follow-up data to 10 years&#34;&gt;


  &lt;img data-src=&#34;https://enochytchen.com/tutorials/extrapolation/relative/article/extrap_rel_fig1_hu563a6fc5b07ca74af1cf00cd17cdbc8c_108321_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;913&#34; height=&#34;664&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Extrapolation by restricting follow-up data to 10 years
  &lt;/figcaption&gt;


&lt;/figure&gt;

The survival was by age groups, where the first 10 years were observed survival and later came the predicted survival. To compare with the empirical Kaplan-Meier curves, the figure below demonstrates the extrapolation.&lt;/p&gt;






  
  











&lt;figure id=&#34;figure-comparing-extrapolation-with-empirical-k-m-curve&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://enochytchen.com/tutorials/extrapolation/relative/article/extrap_rel_fig2_hu8007263a7dbdafca00725d525ecfdc60_102910_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Comparing extrapolation with empirical K-M curve&#34;&gt;


  &lt;img data-src=&#34;https://enochytchen.com/tutorials/extrapolation/relative/article/extrap_rel_fig2_hu8007263a7dbdafca00725d525ecfdc60_102910_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;913&#34; height=&#34;664&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Comparing extrapolation with empirical K-M curve
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Extrapolation within relative survival framework is more robust than all-cause survival. In comparison with the figure in 
&lt;a href=&#34;https://http://enochytchen.com/tutorials/extrapolation/allcause/extrapolating_all/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Extrapolating survival with stpm2 (Part 1)&lt;/a&gt;, we could observe that the extrapolated survival curves deviate less from the empirical K-M curves.&lt;/p&gt;
&lt;p&gt;You may wonder it does not seem to be much different from each other. However, due to the maximum 20 years of follow-up in this dataset, we were not able to generate the empirical curve beyond 20 years. If another dataset containing a longer follow-up period is used, we project that extrapolation in all-cause survival would deviate more, resulting uncertainty in prediction.&lt;/p&gt;
&lt;p&gt;So far we have briefly compare the difference between extrapolating survival in all-cause survival and in relative survival. But what makes relative survival more plausible for extrapolation? Please check the 
&lt;a href=&#34;https://enochytchen.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;next post: Why makes extrapolating relative survival more precise?&lt;/a&gt; for explanation!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Population mortality projection</title>
      <link>https://enochytchen.com/tutorials/extrapolation/data_prep/popmort_projection/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://enochytchen.com/tutorials/extrapolation/data_prep/popmort_projection/</guid>
      <description>&lt;p&gt;The codes used in this post are available 
&lt;a href=&#34;http://enochytchen.com/directory/stata/popmort_projection.do&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
